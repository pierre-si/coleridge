{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd02820280be186ab661f9de35bd01829c341881105846ede977025339161cc4480",
   "display_name": "Python 3.9.2 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Transformer on the full-sentences extracts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH+'train-with-sentence.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Id  \\\n",
       "0     0007f880-0a9b-492d-9a58-76eb0b0e0bd7   \n",
       "1     0008656f-0ba2-4632-8602-3017b44c2e90   \n",
       "2     000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "3     000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "4     000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "...                                    ...   \n",
       "2320  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2321  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2322  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2323  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2324  0b8b9d78-238e-48fc-920a-af70ad6d254b   \n",
       "\n",
       "                                          section_title  \\\n",
       "0                                          Introduction   \n",
       "1                                     LITERATURE REVIEW   \n",
       "2                                            Highlights   \n",
       "3        Example: Farm Income and Farm Household Wealth   \n",
       "4                                        Study subjects   \n",
       "...                                                 ...   \n",
       "2320  Use of GIS to Assess Vulnerability to Sea Leve...   \n",
       "2321  Use of GIS to Assess Vulnerability to Sea Leve...   \n",
       "2322                                   Data and Methods   \n",
       "2323                                                 4.   \n",
       "2324                                                NaN   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     in fact organizations are now identifying digi...   \n",
       "1     international studies on student achievement s...   \n",
       "2     1 manages access to results of the agricultura...   \n",
       "3     the agricultural resources management survey a...   \n",
       "4     54 neuroimaging and genetic parameters in adni...   \n",
       "...                                                 ...   \n",
       "2320  the use of noaa s slosh model for local vulner...   \n",
       "2321  an early example of an effective use of noaa s...   \n",
       "2322  to assess the exposure of sarasota county to c...   \n",
       "2323  county emergency managers also use output from...   \n",
       "2324  in fact 60 percent of older first time communi...   \n",
       "\n",
       "                                          dataset_label  label_length  \n",
       "0     program for the international assessment of ad...            62  \n",
       "1     trends in international mathematics and scienc...            53  \n",
       "2              agricultural resources management survey            40  \n",
       "3              agricultural resources management survey            40  \n",
       "4                                                  adni             4  \n",
       "...                                                 ...           ...  \n",
       "2320                                        slosh model            11  \n",
       "2321                                        slosh model            11  \n",
       "2322                                        slosh model            11  \n",
       "2323                                        slosh model            11  \n",
       "2324  beginning postsecondary students longitudinal ...            51  \n",
       "\n",
       "[2325 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>section_title</th>\n      <th>sentence</th>\n      <th>dataset_label</th>\n      <th>label_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n      <td>Introduction</td>\n      <td>in fact organizations are now identifying digi...</td>\n      <td>program for the international assessment of ad...</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n      <td>LITERATURE REVIEW</td>\n      <td>international studies on student achievement s...</td>\n      <td>trends in international mathematics and scienc...</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n      <td>Highlights</td>\n      <td>1 manages access to results of the agricultura...</td>\n      <td>agricultural resources management survey</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n      <td>Example: Farm Income and Farm Household Wealth</td>\n      <td>the agricultural resources management survey a...</td>\n      <td>agricultural resources management survey</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n      <td>Study subjects</td>\n      <td>54 neuroimaging and genetic parameters in adni...</td>\n      <td>adni</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2320</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Use of GIS to Assess Vulnerability to Sea Leve...</td>\n      <td>the use of noaa s slosh model for local vulner...</td>\n      <td>slosh model</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2321</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Use of GIS to Assess Vulnerability to Sea Leve...</td>\n      <td>an early example of an effective use of noaa s...</td>\n      <td>slosh model</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2322</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Data and Methods</td>\n      <td>to assess the exposure of sarasota county to c...</td>\n      <td>slosh model</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2323</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>4.</td>\n      <td>county emergency managers also use output from...</td>\n      <td>slosh model</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2324</th>\n      <td>0b8b9d78-238e-48fc-920a-af70ad6d254b</td>\n      <td>NaN</td>\n      <td>in fact 60 percent of older first time communi...</td>\n      <td>beginning postsecondary students longitudinal ...</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n<p>2325 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Generate tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokens(sentence, label):\n",
    "    tokens_sequence = ['O'] * len(sentence.split())\n",
    "    start_char = sentence.find(label)\n",
    "    start_token = len(sentence[:start_char].split())\n",
    "\n",
    "    label_len = len(label.split())\n",
    "    tokens_sequence[start_token:start_token+label_len] = ['D']*label_len\n",
    "    return tokens_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "tags = []\n",
    "for i, row in df.iterrows():\n",
    "    texts.append(row.sentence.split())\n",
    "    tags.append(generate_tokens(row.sentence, row.dataset_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Id  \\\n",
       "0     0007f880-0a9b-492d-9a58-76eb0b0e0bd7   \n",
       "1     0008656f-0ba2-4632-8602-3017b44c2e90   \n",
       "2     000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "3     000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "4     000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "...                                    ...   \n",
       "2320  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2321  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2322  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2323  0b8a6c78-b4ef-4d11-b215-318a60583fbb   \n",
       "2324  0b8b9d78-238e-48fc-920a-af70ad6d254b   \n",
       "\n",
       "                                          section_title  \\\n",
       "0                                          Introduction   \n",
       "1                                     LITERATURE REVIEW   \n",
       "2                                            Highlights   \n",
       "3        Example: Farm Income and Farm Household Wealth   \n",
       "4                                        Study subjects   \n",
       "...                                                 ...   \n",
       "2320  Use of GIS to Assess Vulnerability to Sea Leve...   \n",
       "2321  Use of GIS to Assess Vulnerability to Sea Leve...   \n",
       "2322                                   Data and Methods   \n",
       "2323                                                 4.   \n",
       "2324                                                NaN   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     in fact organizations are now identifying digi...   \n",
       "1     international studies on student achievement s...   \n",
       "2     1 manages access to results of the agricultura...   \n",
       "3     the agricultural resources management survey a...   \n",
       "4     54 neuroimaging and genetic parameters in adni...   \n",
       "...                                                 ...   \n",
       "2320  the use of noaa s slosh model for local vulner...   \n",
       "2321  an early example of an effective use of noaa s...   \n",
       "2322  to assess the exposure of sarasota county to c...   \n",
       "2323  county emergency managers also use output from...   \n",
       "2324  in fact 60 percent of older first time communi...   \n",
       "\n",
       "                                          dataset_label  label_length  \\\n",
       "0     program for the international assessment of ad...            62   \n",
       "1     trends in international mathematics and scienc...            53   \n",
       "2              agricultural resources management survey            40   \n",
       "3              agricultural resources management survey            40   \n",
       "4                                                  adni             4   \n",
       "...                                                 ...           ...   \n",
       "2320                                        slosh model            11   \n",
       "2321                                        slosh model            11   \n",
       "2322                                        slosh model            11   \n",
       "2323                                        slosh model            11   \n",
       "2324  beginning postsecondary students longitudinal ...            51   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [in, fact, organizations, are, now, identifyin...   \n",
       "1     [international, studies, on, student, achievem...   \n",
       "2     [1, manages, access, to, results, of, the, agr...   \n",
       "3     [the, agricultural, resources, management, sur...   \n",
       "4     [54, neuroimaging, and, genetic, parameters, i...   \n",
       "...                                                 ...   \n",
       "2320  [the, use, of, noaa, s, slosh, model, for, loc...   \n",
       "2321  [an, early, example, of, an, effective, use, o...   \n",
       "2322  [to, assess, the, exposure, of, sarasota, coun...   \n",
       "2323  [county, emergency, managers, also, use, outpu...   \n",
       "2324  [in, fact, 60, percent, of, older, first, time...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, D, D, D, D, D, D, D, O, ...  \n",
       "2     [O, O, O, O, O, O, O, D, D, D, D, O, O, O, O, ...  \n",
       "3     [O, D, D, D, D, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, O, O, O, D, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "2320  [O, O, O, O, O, D, D, O, O, O, O, O, O, O, O, ...  \n",
       "2321  [O, O, O, O, O, O, O, O, O, O, D, D, O, O, O, ...  \n",
       "2322  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2323  [O, O, O, O, O, O, O, O, D, D, O, O, O, O, O, ...  \n",
       "2324  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[2325 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>section_title</th>\n      <th>sentence</th>\n      <th>dataset_label</th>\n      <th>label_length</th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n      <td>Introduction</td>\n      <td>in fact organizations are now identifying digi...</td>\n      <td>program for the international assessment of ad...</td>\n      <td>62</td>\n      <td>[in, fact, organizations, are, now, identifyin...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n      <td>LITERATURE REVIEW</td>\n      <td>international studies on student achievement s...</td>\n      <td>trends in international mathematics and scienc...</td>\n      <td>53</td>\n      <td>[international, studies, on, student, achievem...</td>\n      <td>[O, O, O, O, O, O, O, D, D, D, D, D, D, D, O, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n      <td>Highlights</td>\n      <td>1 manages access to results of the agricultura...</td>\n      <td>agricultural resources management survey</td>\n      <td>40</td>\n      <td>[1, manages, access, to, results, of, the, agr...</td>\n      <td>[O, O, O, O, O, O, O, D, D, D, D, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n      <td>Example: Farm Income and Farm Household Wealth</td>\n      <td>the agricultural resources management survey a...</td>\n      <td>agricultural resources management survey</td>\n      <td>40</td>\n      <td>[the, agricultural, resources, management, sur...</td>\n      <td>[O, D, D, D, D, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n      <td>Study subjects</td>\n      <td>54 neuroimaging and genetic parameters in adni...</td>\n      <td>adni</td>\n      <td>4</td>\n      <td>[54, neuroimaging, and, genetic, parameters, i...</td>\n      <td>[O, O, O, O, O, O, D, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2320</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Use of GIS to Assess Vulnerability to Sea Leve...</td>\n      <td>the use of noaa s slosh model for local vulner...</td>\n      <td>slosh model</td>\n      <td>11</td>\n      <td>[the, use, of, noaa, s, slosh, model, for, loc...</td>\n      <td>[O, O, O, O, O, D, D, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2321</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Use of GIS to Assess Vulnerability to Sea Leve...</td>\n      <td>an early example of an effective use of noaa s...</td>\n      <td>slosh model</td>\n      <td>11</td>\n      <td>[an, early, example, of, an, effective, use, o...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, D, D, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2322</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>Data and Methods</td>\n      <td>to assess the exposure of sarasota county to c...</td>\n      <td>slosh model</td>\n      <td>11</td>\n      <td>[to, assess, the, exposure, of, sarasota, coun...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2323</th>\n      <td>0b8a6c78-b4ef-4d11-b215-318a60583fbb</td>\n      <td>4.</td>\n      <td>county emergency managers also use output from...</td>\n      <td>slosh model</td>\n      <td>11</td>\n      <td>[county, emergency, managers, also, use, outpu...</td>\n      <td>[O, O, O, O, O, O, O, O, D, D, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2324</th>\n      <td>0b8b9d78-238e-48fc-920a-af70ad6d254b</td>\n      <td>NaN</td>\n      <td>in fact 60 percent of older first time communi...</td>\n      <td>beginning postsecondary students longitudinal ...</td>\n      <td>51</td>\n      <td>[in, fact, 60, percent, of, older, first, time...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2325 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df['tokens'] = texts\n",
    "df['ner_tags'] = tags\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = df[df['tokens'].apply(len) <= 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1851 463\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "train_df, val_df = train_test_split(long_df, test_size=.2, random_state=seed)\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "source": [
    "# Writing data to file\n",
    "To be used with the run_ner script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json('../input/small/ner_train-128.json', orient='records', lines=True)\n",
    "val_df.to_json('../input/small/ner_val-128.json', orient='records', lines=True)"
   ]
  },
  {
   "source": [
    "# old"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_texts = [text for text in texts if len(text) <= 128]\n",
    "short_tags = [tag for text, tag in zip(texts, tags) if len(text) <= 128]\n",
    "long_texts_idx = [i for i in range(len(texts)) if len(texts[i]) > 128]\n",
    "\n",
    "texts = short_texts\n",
    "tags = short_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(filename, texts, tags):\n",
    "    with open(filename, 'w') as f:\n",
    "        for text, tag in zip(texts, tags):\n",
    "            json_el = {'tokens': text, 'tags': tag}\n",
    "            json.dump(json_el, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1851 463\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2, random_state=seed)\n",
    "print(len(train_texts), len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(DATA_PATH+'ner_train.json', train_texts, train_tags)\n",
    "save_json(DATA_PATH+'ner_val.json', val_texts, val_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json('cleaned_ner_train_small.json', train_texts[:4000], train_tags[:4000])\n",
    "save_json('cleaned_ner_val.json', val_texts[:2000], val_tags[:2000])"
   ]
  },
  {
   "source": [
    "# Training in the notebook\n",
    "buggy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in tags for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "max_length = 512\n",
    "train_encodings = tokenizer(train_texts, max_length=max_length, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, max_length=max_length, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "NumPy boolean array indexing assignment cannot assign 12 input values to the 11 output values where the mask is true",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-465a3f04008d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-465a3f04008d>\u001b[0m in \u001b[0;36mencode_tags\u001b[0;34m(tags, encodings)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(doc_enc_labels.shape, len(doc_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# set labels whose first offset position is 0 and the second is not 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mencoded_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NumPy boolean array indexing assignment cannot assign 12 input values to the 11 output values where the mask is true"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_tags(tags, encodings):\n",
    "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "        #print(doc_enc_labels.shape, len(doc_labels))\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "train_labels = encode_tags(train_tags, train_encodings)\n",
    "val_labels = encode_tags(val_tags, val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def tokenize_and_align_labels(examples):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            examples[text_column_name],\n",
    "            padding=padding,\n",
    "            truncation=True,\n",
    "            # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "            is_split_into_words=True,\n",
    "        )\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[label_column_name]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "                # ignored in the loss function.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                # We set the label for the first token of each word.\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label_to_id[label[word_idx]])\n",
    "                # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "                # the label_all_tokens flag.\n",
    "                else:\n",
    "                    label_ids.append(label_to_id[label[word_idx]] if data_args.label_all_tokens else -100)\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "            labels.append(label_ids)\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs"
   ]
  }
 ]
}